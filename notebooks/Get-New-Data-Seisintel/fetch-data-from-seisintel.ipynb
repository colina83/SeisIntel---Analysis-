{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survey Id', 'Parent Id', 'Survey Name', 'Type', 'Activity', 'Company',\n",
       "       'Survey Company', 'Vessel', 'Client', 'Country', 'Complete',\n",
       "       'Mobilisation Location', 'Mobilisation Start', 'Deployment Start',\n",
       "       'Production Start', 'Production End', 'Retrieval End',\n",
       "       'Demobilisation End', 'Demobilisation Location', 'Number of Streamers',\n",
       "       'Streamer Separation', 'Streamer Length', 'Sail Line Separation',\n",
       "       'Report', 'Combo Report', 'Tides', 'Ocean Current', 'FFSQKM',\n",
       "       'FFSQKM Method', 'Shot Patch SQKM', 'Shotpatch Method',\n",
       "       'FF Minimum Water Depth (m)', 'FF Maximum Water Depth (m)', 'CentreLAT',\n",
       "       'CentreLONG', 'Replay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"seisintel_selected_surveys_OBN.csv\")\n",
    "def fetch_vessel_row(df, name, status):\n",
    "    df_filter  = df[df[\"Vessel\"].str.contains(name) & df[\"Complete\"].str.contains(status)]\n",
    "    return df_filter\n",
    "\n",
    "def fetch_by_survey_name(df, name):\n",
    "    df_filter  = df[df[\"Survey Name\"].str.contains(name)]\n",
    "    return df_filter\n",
    "\n",
    "def fetch_by_survey_name_year(df, name,year):\n",
    "    df_filter  = df[df[\"Survey Name\"].str.contains(name) & df[\"Mobilisation Start\"].str.contains(year)]\n",
    "    return df_filter\n",
    "\n",
    "def fetch_vessels_in_survey(df,type):\n",
    "    df_filter  = df[df[\"Activity\"].str.contains(type)]\n",
    "    return df_filter\n",
    "\n",
    "def fetch_vessel_info(df, survey_id):\n",
    "    df_filter  = df[df[\"Survey Id\"].str.contains(survey_id)]\n",
    "    return df_filter\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_survey_info = fetch_by_survey_name_year(df,\"Mumbai High OBN\",\"2024\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"KG-DWN-98/2 Cluster-2 OBN\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Stones 4D\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Edvard Grieg 4D\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Thunder Horse 4D OBN\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"OML 130 Preowei OBN\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Engagement 6\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Inception\")\n",
    "df_survey_info = fetch_by_survey_name(df,\"Jack\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Oseburg\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Green Canyon\")\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Kaikias\")\n",
    "# survey_id = list(df_survey_info[\"Survey Id\"])[0]\n",
    "# df_survey_info = fetch_by_survey_name(df,\"Sepia\")\n",
    "# for index, row in df_survey_info.iterrows():\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392        Fulmar Explorer\n",
       "393    Harvey Intervention\n",
       "394        Olympic Artemis\n",
       "395    Harvey Intervention\n",
       "Name: Vessel, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_vessels_in_survey = df_survey_info\n",
    "vessel_names = list(df_node_vessels_in_survey['Vessel'])\n",
    "df_node_vessels_in_survey['Vessel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23US_02765', '23US_02739', '23US_02820', '24US_02829']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_ids = list(df_node_vessels_in_survey[\"Survey Id\"])\n",
    "survey_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fulmar Explorer': 'Galveston -  UNITED STATES',\n",
       " 'Harvey Intervention': 'Port Fourchon -  UNITED STATES',\n",
       " 'Olympic Artemis': 'Galveston -  UNITED STATES'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_location_of_each_vessel = list(df_node_vessels_in_survey[\"Mobilisation Location\"])\n",
    "activity_of_the_vessel = list(df_node_vessels_in_survey[\"Activity\"])\n",
    "start_points_per_vessel = {}\n",
    "survey_id_per_vessel = {}\n",
    "activity_per_vessel = {}\n",
    "i = 0\n",
    "for vessel in vessel_names:\n",
    "    start_points_per_vessel[vessel] = start_location_of_each_vessel[i]\n",
    "    survey_id_per_vessel[vessel] = survey_ids[i]\n",
    "    activity_per_vessel[survey_ids[i]] = activity_of_the_vessel[i]\n",
    "    i+=1\n",
    "start_points_per_vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fulmar Explorer': '23US_02765',\n",
       " 'Harvey Intervention': '24US_02829',\n",
       " 'Olympic Artemis': '23US_02820'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_id_per_vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23US_02765': 'Source',\n",
       " '23US_02739': 'Node Layout',\n",
       " '23US_02820': 'Node Layout',\n",
       " '24US_02829': 'Node Retrieval'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_per_vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just so that all the downloads are moved into a specific folder\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in\n"
     ]
    }
   ],
   "source": [
    "# if there are issues with the chromedriver - update it with the latest compatible version of your chrome app\n",
    "og_url = \"https://portal.seisintel.com/#/\"\n",
    "login_url = og_url+\"login/\"\n",
    "path_url = og_url+\"path/\"\n",
    "# \"https://portal.seisintel.com/#/path/\"\n",
    "cService  = webdriver.ChromeService(executable_path=\".\\\\chromedriver.exe\") \n",
    "driver = webdriver.Chrome(service = cService)\n",
    "driver.get(login_url) \n",
    "wait = WebDriverWait(driver, 100)\n",
    "# login to the seisintel page\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Login']\"))).send_keys(\"rohith.nomula@tgs.com\")\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Password']\"))).send_keys(\"50fd47a7\")\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@ng-click='vm.doLogin()']\"))).click()\n",
    "# if this part is done - write error checking here\n",
    "print(\"Logged in\")\n",
    "# After login - that part is only once\n",
    "# Now we try to access different vessels using a unqiue survey_id and download the data \n",
    "# This can be more effecient if we search from a complete project and find all the download links then and there \n",
    "# So we can figure out how long does it take to process a specific project\n",
    "for survey_id in survey_ids:\n",
    "    # try:\n",
    "    driver.get(path_url+survey_id) \n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Download']\"))).click()\n",
    "    # We might need csv as well as geojson data - need to explore a bit into KML data and see if has any additional info\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='CSV']\"))).click()\n",
    "    time.sleep(2)\n",
    "    # The plot is very bad - we can make it look good but we have geojson for this exact same reason\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Download']\"))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='GeoJSON']\"))).click()\n",
    "    time.sleep(2)\n",
    "    # except:\n",
    "    #     move_all_files_to_download_folder()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
